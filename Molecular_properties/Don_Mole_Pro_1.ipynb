{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import scipy.signal as sg\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to implement a way to calculate group mae\n",
    "def train_model_regression(X, X_test, y, params, folds, molecules, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, groups = molecules)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= folds.n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= folds.n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read different given datasets and public accessible datasets and merge them together to form training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('E:/kaggle/Molecular_properties/simple-molecular-geometry-features/train_geom.csv', index_col='id')\n",
    "test1 = pd.read_csv('E:/kaggle/Molecular_properties/simple-molecular-geometry-features/test_geom.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('E:/kaggle/Molecular_properties/Data_use/train_bonds_QM9_neighbor_selected_all.csv')\n",
    "test = pd.read_csv('E:/kaggle/Molecular_properties/Data_use/test_bonds_QM9_neighbor_selected_all.csv')\n",
    "\n",
    "train.fillna(0, inplace = True)\n",
    "test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = train1.pop('scalar_coupling_constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_molecules = pd.read_csv('E:/kaggle/Molecular_properties/Data_use/molecules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_coupling = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/scalar_coupling_contributions.csv')\n",
    "scalar_coupling.head()\n",
    "y_fc = scalar_coupling['fc']\n",
    "y_sd = scalar_coupling['sd']\n",
    "y_pso = scalar_coupling['pso']\n",
    "y_dso = scalar_coupling['dso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_coupling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test1\n",
    "del train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/structures.csv')\n",
    "display(structures.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there is a ratio between the electrons distance to 'N' and 'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipole_moments = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/dipole_moments.csv')\n",
    "dipole_moments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnetic_shielding = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/magnetic_shielding_tensors.csv')\n",
    "magnetic_shielding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mulliken_charges = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/mulliken_charges.csv')\n",
    "mulliken_charges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/potential_energy.csv')\n",
    "potential.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9 = pd.read_csv('E:/kaggle/Molecular_properties/qm9-processed/QM9_processed.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9 = reduce_mem_usage(QM9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9_cols = QM9.columns.values[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QM9 = QM9[QM9_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bonds = pd.read_csv('E:/kaggle/Molecular_properties/data-bonds/train_bonds.csv', index_col='id')\n",
    "test_bonds = pd.read_csv('E:/kaggle/Molecular_properties/data-bonds/test_bonds.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bonds = reduce_mem_usage(train_bonds)\n",
    "test_bonds = reduce_mem_usage(test_bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tokeep_bonds = ['EN_0', 'rad_0', #'n_bonds_0', 'bond_lengths_mean_0', 'nbond_unpaired_diff_0',\n",
    "                     'EN_1', 'rad_1', #'n_bonds_1', 'bond_lengths_mean_1', 'nbond_unpaired_diff_1',\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bonds = train_bonds[cols_tokeep_bonds]\n",
    "test_bonds = test_bonds[cols_tokeep_bonds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neighbor = pd.read_csv('E:/kaggle/Molecular_properties/data-neighbor/train_neighbor.csv', index_col='id')\n",
    "test_neighbor = pd.read_csv('E:/kaggle/Molecular_properties/data-neighbor/test_neighbor.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1203.88 Mb (41.6% reduction)\n",
      "Mem. usage decreased to 637.99 Mb (41.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_neighbor = reduce_mem_usage(train_neighbor)\n",
    "test_neighbor = reduce_mem_usage(test_neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = pd.read_csv('E:/kaggle/Molecular_properties/angle-and-dihedral-for-the-champs-structures/angles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, QM9, how = 'left', left_index = True, right_index = True)\n",
    "test = pd.merge(test, QM9, how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_bonds, how = 'left', left_index = True, right_index = True)\n",
    "test = pd.merge(test, test_bonds, how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['atom_index_0'] = train1['atom_index_0']\n",
    "train['atom_index_1'] = train1['atom_index_1']\n",
    "train['molecule_name'] = train1['molecule_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['atom_index_0'] = test1['atom_index_0']\n",
    "test['atom_index_1'] = test1['atom_index_1']\n",
    "test['molecule_name'] = test1['molecule_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_neighbor, how = 'left', left_on = ['molecule_name', 'atom_index_0', 'atom_index_1'], right_on = ['molecule_name', 'atom_index_0', 'atom_index_1'])\n",
    "test = pd.merge(test, test_neighbor, how = 'left', left_on = ['molecule_name', 'atom_index_0', 'atom_index_1'], right_on = ['molecule_name', 'atom_index_0', 'atom_index_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1972.41 Mb (35.2% reduction)\n",
      "Mem. usage decreased to 1051.37 Mb (35.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = structures['atom'].unique()\n",
    "df_atoms = pd.DataFrame(index=atoms)\n",
    "df_atoms['mass'] = [12, 1, 14, 16, 19]\n",
    "df_atoms['unpaired_electrons'] = [2, 1, 3, 2, 1]\n",
    "df_atoms['bonding_electrons_1'] = [-4, 1, -3, -2, -1]\n",
    "df_atoms['bonding_electrons_2'] = [4, 1, -3, -2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate features from different data sets\n",
    "Features to try: \n",
    "1. Total mass of a molecule and mass of a atom \n",
    "2. Size of molecule (This is not well defined)\n",
    "3. Free electron of an atom\n",
    "\n",
    "Finish generating mass, charge and size features of molecules (weighted and un-weighted) and start do some modeling!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the atom structure data into train and test files\n",
    "\n",
    "def map_atom_info(df, atom_idx):\n",
    "    df = pd.merge(df, structures, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    \n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    df = df.rename(columns={\n",
    "                            #'atom': f'atom_{atom_idx}',\n",
    "                            'x': f'x_{atom_idx}',\n",
    "                            'y': f'y_{atom_idx}',\n",
    "                            'z': f'z_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "train = map_atom_info(train, 0)\n",
    "train = map_atom_info(train, 1)\n",
    "\n",
    "test = map_atom_info(test, 0)\n",
    "test = map_atom_info(test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['atom_x', 'atom_y'], axis = 1, inplace = True)\n",
    "test.drop(['atom_x', 'atom_y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate distance between atoms\n",
    "% time\n",
    "\n",
    "train['dist'] = ((train['x_1'] - train['x_0']) ** 2 + (train['y_1'] - train['y_0']) ** 2 + (train['z_1'] - train['z_0']) ** 2) ** 0.5\n",
    "test['dist'] = ((test['x_1'] - test['x_0']) ** 2 + (test['y_1'] - test['y_0']) ** 2 + (test['z_1'] - test['z_0']) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation features in a molecule\n",
    "def map_structures_agg_info(df):\n",
    "    \n",
    "    agg_func = {'atom': 'count',\n",
    "            'x': ['max', 'min', 'std'],\n",
    "            'y': ['max', 'min', 'std'],\n",
    "            'z': ['max', 'min', 'std'],\n",
    "            #'dist': ['max', 'min', 'std']\n",
    "           }\n",
    "    \n",
    "    intermediate = structures.groupby('molecule_name').agg(agg_func)\n",
    "    intermediate.columns = ['_'.join(col).strip() for col in intermediate.columns.values]\n",
    "    intermediate.reset_index(inplace = True)\n",
    "    \n",
    "    intermediate['size_x'] = intermediate['x_max'] - intermediate['x_min']\n",
    "    intermediate['size_y'] = intermediate['y_max'] - intermediate['y_min']\n",
    "    intermediate['size_z'] = intermediate['z_max'] - intermediate['z_min']\n",
    "    intermediate['size'] = (intermediate['size_x'] ** 2 + intermediate['size_y'] ** 2 + intermediate['size_z'] ** 2) ** 0.5\n",
    "    \n",
    "    for col in intermediate.columns.values:\n",
    "        if col == 'molecule_name':\n",
    "            continue\n",
    "        intermediate.rename({col: 'whole' + '_' + col}, axis=1, inplace=True)\n",
    "\n",
    "    df = pd.merge(df, intermediate, how = 'left',\n",
    "                  left_on  = ['molecule_name'],\n",
    "                  right_on = ['molecule_name'])\n",
    "    \n",
    "    for atom in atoms:    \n",
    "        if atom == 'F':\n",
    "            continue\n",
    "        intermediate = structures[structures['atom'] == atom].groupby('molecule_name').agg(agg_func)\n",
    "        intermediate.columns = ['_'.join(col).strip() for col in intermediate.columns.values]\n",
    "        intermediate.reset_index(inplace = True)\n",
    "\n",
    "        intermediate['size_x'] = intermediate['x_max'] - intermediate['x_min']\n",
    "        intermediate['size_y'] = intermediate['y_max'] - intermediate['y_min']\n",
    "        intermediate['size_z'] = intermediate['z_max'] - intermediate['z_min']\n",
    "        intermediate['size'] = (intermediate['size_x'] ** 2 + intermediate['size_y'] ** 2 + intermediate['size_z'] ** 2) ** 0.5\n",
    "\n",
    "        for col in intermediate.columns.values:\n",
    "            if col == 'molecule_name':\n",
    "                continue\n",
    "            intermediate.rename({col: str(atom) + '_' + col}, axis=1, inplace=True)\n",
    "\n",
    "        df = pd.merge(df, intermediate, how = 'left',\n",
    "                  left_on  = ['molecule_name'],\n",
    "                  right_on = ['molecule_name'])\n",
    "    \n",
    "    df.fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "train = map_structures_agg_info(train)\n",
    "\n",
    "test = map_structures_agg_info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_more = pd.merge(structures, df_atoms, how = 'left',\n",
    "                  left_on  = ['atom'],\n",
    "                  right_on = df_atoms.index)\n",
    "col_coordinate = ['x', 'y', 'z']\n",
    "col_multiply = ['mass', 'unpaired_electrons', 'bonding_electrons_1', 'bonding_electrons_2']\n",
    "\n",
    "for coordinate in col_coordinate:\n",
    "    for col in col_multiply:\n",
    "        structures_more[col + '_' + coordinate] = structures_more[col] * structures_more[coordinate]\n",
    "\n",
    "structures_more.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can always engineer these features depending on atoms\n",
    "\n",
    "def map_structure_atoms_info(df):\n",
    "    agg_func = {'mass': 'sum',\n",
    "                'unpaired_electrons': 'sum',\n",
    "                'bonding_electrons_1': 'sum',\n",
    "                'bonding_electrons_2': 'sum',\n",
    "                'mass_x': 'sum',\n",
    "                'mass_y': 'sum',\n",
    "                'mass_z': 'sum',\n",
    "                'unpaired_electrons_x': 'sum',\n",
    "                'unpaired_electrons_y': 'sum',\n",
    "                'unpaired_electrons_z': 'sum',\n",
    "                'bonding_electrons_1_x': 'sum',\n",
    "                'bonding_electrons_1_y': 'sum',\n",
    "                'bonding_electrons_1_z': 'sum',\n",
    "                'bonding_electrons_2_x': 'sum',\n",
    "                'bonding_electrons_2_y': 'sum',\n",
    "                'bonding_electrons_2_z': 'sum',\n",
    "            \n",
    "           }\n",
    "    \n",
    "    intermediate = structures_more.groupby('molecule_name').agg(agg_func).reset_index()\n",
    "    #intermediate.columns = ['_'.join(col).strip() for col in intermediate.columns.values]\n",
    "    #intermediate.reset_index(inplace = True)\n",
    "    \n",
    "    for col in intermediate.columns.values:\n",
    "        if col == 'molecule_name':\n",
    "            continue\n",
    "        intermediate.rename({col: 'whole' + '_' + col + '_' + 'sum'}, axis=1, inplace=True)\n",
    "    \n",
    "    intermediate['whole_mass_size'] = (intermediate['whole_mass_x_sum'] ** 2 + intermediate['whole_mass_y_sum'] ** 2 + intermediate['whole_mass_z_sum'] ** 2) ** 0.5\n",
    "    intermediate['whole_unpaired_electrons_size'] = (intermediate['whole_unpaired_electrons_x_sum'] ** 2 + intermediate['whole_unpaired_electrons_y_sum'] ** 2 + intermediate['whole_unpaired_electrons_z_sum'] ** 2) ** 0.5\n",
    "    intermediate['whole_bonding_electrons_1_size'] = (intermediate['whole_bonding_electrons_1_x_sum'] ** 2 + intermediate['whole_bonding_electrons_1_y_sum'] ** 2 + intermediate['whole_bonding_electrons_1_z_sum'] ** 2) ** 0.5\n",
    "    intermediate['whole_bonding_electrons_2_size'] = (intermediate['whole_bonding_electrons_2_x_sum'] ** 2 + intermediate['whole_bonding_electrons_2_y_sum'] ** 2 + intermediate['whole_bonding_electrons_2_z_sum'] ** 2) ** 0.5\n",
    "\n",
    "    df = pd.merge(df, intermediate, how = 'left',\n",
    "                  left_on  = ['molecule_name'],\n",
    "                  right_on = ['molecule_name'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = map_structure_atoms_info(train)\n",
    "\n",
    "test = map_structure_atoms_info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More distance related aggregation features\n",
    "def train_dist_info(df):\n",
    "    \n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['molecule_name'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    \n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    \n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    \n",
    "    df = reduce_mem_usage(df)\n",
    "    return df\n",
    "\n",
    "train = train_dist_info(train)\n",
    "\n",
    "test = train_dist_info(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle features in a molecule\n",
    "def train_angle_info(df):\n",
    "    \n",
    "    \n",
    "    df['molecule_bond_angle_axis_mean'] = df.groupby('molecule_name')['bond_angle_axis'].transform('mean')\n",
    "    df['molecule_bond_angle_axis_min'] = df.groupby('molecule_name')['bond_angle_axis'].transform('min')\n",
    "    df['molecule_bond_angle_axis_max'] = df.groupby('molecule_name')['bond_angle_axis'].transform('max')\n",
    "    \n",
    "    df['molecule_bond_angle_plane_mean'] = df.groupby('molecule_name')['bond_angle_plane'].transform('mean')\n",
    "    df['molecule_bond_angle_plane_min'] = df.groupby('molecule_name')['bond_angle_plane'].transform('min')\n",
    "    df['molecule_bond_angle_plane_max'] = df.groupby('molecule_name')['bond_angle_plane'].transform('max')\n",
    "    \n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_axis'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_mean_diff'] = df[f'molecule_atom_index_0_bond_angle_axis_mean'] - df['bond_angle_axis']\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_max'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_axis'].transform('max')\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_max_diff'] = df[f'molecule_atom_index_0_bond_angle_axis_max'] - df['bond_angle_axis']\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_min'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_axis'].transform('min')\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_min_diff'] = df[f'molecule_atom_index_0_bond_angle_axis_min'] - df['bond_angle_axis']\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_std'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_axis'].transform('std')\n",
    "    df[f'molecule_atom_index_0_bond_angle_axis_std_diff'] = df[f'molecule_atom_index_0_bond_angle_axis_std'] - df['bond_angle_axis']\n",
    "    \n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_axis'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_mean_diff'] = df[f'molecule_atom_index_1_bond_angle_axis_mean'] - df['bond_angle_axis']\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_max'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_axis'].transform('max')\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_max_diff'] = df[f'molecule_atom_index_1_bond_angle_axis_max'] - df['bond_angle_axis']\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_min'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_axis'].transform('min')\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_min_diff'] = df[f'molecule_atom_index_1_bond_angle_axis_min'] - df['bond_angle_axis']\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_std'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_axis'].transform('std')\n",
    "    df[f'molecule_atom_index_1_bond_angle_axis_std_diff'] = df[f'molecule_atom_index_1_bond_angle_axis_std'] - df['bond_angle_axis']\n",
    "    \n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_plane'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_mean_diff'] = df[f'molecule_atom_index_0_bond_angle_plane_mean'] - df['bond_angle_plane']\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_max'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_plane'].transform('max')\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_max_diff'] = df[f'molecule_atom_index_0_bond_angle_plane_max'] - df['bond_angle_plane']\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_min'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_plane'].transform('min')\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_min_diff'] = df[f'molecule_atom_index_0_bond_angle_plane_min'] - df['bond_angle_plane']\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_std'] = df.groupby(['molecule_name', 'atom_index_0'])['bond_angle_plane'].transform('std')\n",
    "    df[f'molecule_atom_index_0_bond_angle_plane_std_diff'] = df[f'molecule_atom_index_0_bond_angle_plane_std'] - df['bond_angle_plane']\n",
    "    \n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_plane'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_mean_diff'] = df[f'molecule_atom_index_1_bond_angle_plane_mean'] - df['bond_angle_plane']\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_max'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_plane'].transform('max')\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_max_diff'] = df[f'molecule_atom_index_1_bond_angle_plane_max'] - df['bond_angle_plane']\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_min'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_plane'].transform('min')\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_min_diff'] = df[f'molecule_atom_index_1_bond_angle_plane_min'] - df['bond_angle_plane']\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_std'] = df.groupby(['molecule_name', 'atom_index_1'])['bond_angle_plane'].transform('std')\n",
    "    df[f'molecule_atom_index_1_bond_angle_plane_std_diff'] = df[f'molecule_atom_index_1_bond_angle_plane_std'] - df['bond_angle_plane']\n",
    "    \n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(df):\n",
    "    df_p_0 = df[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df[['x_1', 'y_1', 'z_1']].values\n",
    "    \n",
    "    df['dist'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "    df['dist_x'] = (df['x_0'] - df['x_1']) ** 2\n",
    "    df['dist_y'] = (df['y_0'] - df['y_1']) ** 2\n",
    "    df['dist_z'] = (df['z_0'] - df['z_1']) ** 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_closest(df):\n",
    "    cols = [\"molecule_name\",\"atom_index_0\",\"atom_index_1\",'atom_0', 'atom_1', \n",
    "                      \"dist\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\",\n",
    "                     'n_bonds_0', 'n_bonds_1', 'rad_dist_diff',\n",
    "                     'mulliken_atom_0', 'mulliken_atom_1'\n",
    "                     ]\n",
    "    df_temp=df.loc[:, cols].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1', 'atom_index_1': 'atom_index_0',\n",
    "                                       'atom_0': 'atom_1', 'atom_1': 'atom_0',\n",
    "                                       'x_0': 'x_1', 'y_0': 'y_1', 'z_0': 'z_1', 'n_bonds_0': 'n_bonds_1', \n",
    "                                       'x_1': 'x_0', 'y_1': 'y_0', 'z_1': 'z_0', 'n_bonds_1': 'n_bonds_0',\n",
    "                                       'mulliken_atom_0': 'mulliken_atom_1', 'mulliken_atom_1': 'mulliken_atom_0',\n",
    "                                      })\n",
    "    df_temp_ = df_temp_[cols]\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"dist\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['atom_0', 'x_0', 'y_0', 'z_0', 'n_bonds_0', 'min_distance', 'dist',\n",
    "                        'mulliken_atom_0',\n",
    "                         ], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'atom_1': 'atom_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'n_bonds_1': 'n_bonds_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest',\n",
    "                                     'mulliken_atom_1': 'mulliken_closest',\n",
    "                                     'rad_dist_diff': 'rad_dist_diff_closest' \n",
    "                                    })\n",
    "    df_temp.drop_duplicates(subset=['molecule_name', 'atom_index'], inplace = True)\n",
    "    for atom_idx in [0,1]:\n",
    "        df = map_atom_info(df,df_temp, atom_idx)\n",
    "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                        'x_closest': f'x_closest_{atom_idx}',\n",
    "                                        'y_closest': f'y_closest_{atom_idx}',\n",
    "                                        'z_closest': f'z_closest_{atom_idx}',\n",
    "                                        'atom_closest': f'atom_closest_{atom_idx}',\n",
    "                                        'n_bonds_closest': f'n_bonds_closest_{atom_idx}',\n",
    "                                        'mulliken_closest': f'mulliken_closest_{atom_idx}',\n",
    "                                        'rad_dist_diff_closest': f'rad_dist_diff_closest_{atom_idx}',\n",
    "                               })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_cos_features(df):\n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"dist\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"dist\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"dist\"]\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train = distances(train)\n",
    "test = distances(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create closest features\n"
     ]
    }
   ],
   "source": [
    "print('Create closest features')\n",
    "\n",
    "train = create_closest(train)\n",
    "test = create_closest(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create cos features\n"
     ]
    }
   ],
   "source": [
    "print('Create cos features')\n",
    "\n",
    "train = add_cos_features(train)\n",
    "test = add_cos_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coupling features based on Coulomb or Yukawa potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Coulomb'] = train['multiply_mulliken'] / train['dist']\n",
    "test['Coulomb'] = test['multiply_mulliken'] / test['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Yukawa'] = train['Coulomb'] * np.exp(-train['dist'])\n",
    "test['Yukawa'] = test['Coulomb'] * np.exp(-test['dist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse dist features. These features improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['inverse_dist_3'] = 1 / (train['dist'] * train['dist'] * train['dist'])\n",
    "test['inverse_dist_3'] = 1 / (test['dist'] * test['dist'] * test['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['inverse_rad_dist_diff'] = 1/ ((train['dist'] - train['rad_0'] - train['rad_1']) ** 2)\n",
    "test['inverse_rad_dist_diff'] = 1/ ((test['dist'] - test['rad_0'] - test['rad_1']) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['inverse_dist_EN'] = 1/ (train['dist'] * (train['EN_0'] * 0.5 + train['EN_1'] * 0.5) ** 2)\n",
    "test['inverse_dist_EN'] = 1/ (test['dist'] * (test['EN_0'] * 0.5 + test['EN_1'] * 0.5) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mole_idx_0_inverse_dist_sum'] = 1 / (train.groupby(['molecule_name', 'atom_index_0'])['inverse_dist_3'].transform('sum'))\n",
    "train['mole_idx_1_inverse_dist_sum'] = 1 / (train.groupby(['molecule_name', 'atom_index_1'])['inverse_dist_3'].transform('sum'))\n",
    "train['combine_inverse_dist'] = train['mole_idx_0_inverse_dist_sum'] * train['mole_idx_1_inverse_dist_sum'] / (train['mole_idx_0_inverse_dist_sum'] + train['mole_idx_1_inverse_dist_sum'])\n",
    "\n",
    "test['mole_idx_0_inverse_dist_sum'] = 1 / (test.groupby(['molecule_name', 'atom_index_0'])['inverse_dist_3'].transform('sum'))\n",
    "test['mole_idx_1_inverse_dist_sum'] = 1 / (test.groupby(['molecule_name', 'atom_index_1'])['inverse_dist_3'].transform('sum'))\n",
    "test['combine_inverse_dist'] = test['mole_idx_0_inverse_dist_sum'] * test['mole_idx_1_inverse_dist_sum'] / (test['mole_idx_0_inverse_dist_sum'] + test['mole_idx_1_inverse_dist_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mole_idx_0_inverse_rad_dist_diff_sum'] = 1 / (train.groupby(['molecule_name', 'atom_index_0'])['inverse_rad_dist_diff'].transform('sum'))\n",
    "train['mole_idx_1_inverse_rad_dist_diff_sum'] = 1 / (train.groupby(['molecule_name', 'atom_index_1'])['inverse_rad_dist_diff'].transform('sum'))\n",
    "train['combine_inverse_rad_dist_diff'] = train['mole_idx_0_inverse_rad_dist_diff_sum'] * train['mole_idx_1_inverse_rad_dist_diff_sum'] / (train['mole_idx_0_inverse_rad_dist_diff_sum'] + train['mole_idx_1_inverse_rad_dist_diff_sum'])\n",
    "\n",
    "test['mole_idx_0_inverse_rad_dist_diff_sum'] = 1 / (test.groupby(['molecule_name', 'atom_index_0'])['inverse_rad_dist_diff'].transform('sum'))\n",
    "test['mole_idx_1_inverse_rad_dist_diff_sum'] = 1 / (test.groupby(['molecule_name', 'atom_index_1'])['inverse_rad_dist_diff'].transform('sum'))\n",
    "test['combine_inverse_rad_dist_diff'] = test['mole_idx_0_inverse_rad_dist_diff_sum'] * test['mole_idx_1_inverse_rad_dist_diff_sum'] / (test['mole_idx_0_inverse_rad_dist_diff_sum'] + test['mole_idx_1_inverse_rad_dist_diff_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mole_idx_0_inverse_dist_EN_sum'] = 1 / (train.groupby(['molecule_name', 'atom_index_0'])['inverse_dist_EN'].transform('sum'))\n",
    "train['mole_idx_1_inverse_dist_EN_sum'] = 1 / (train.groupby(['molecule_name', 'atom_index_1'])['inverse_dist_EN'].transform('sum'))\n",
    "train['combine_inverse_dist_EN'] = train['mole_idx_0_inverse_dist_EN_sum'] * train['mole_idx_1_inverse_dist_EN_sum'] / (train['mole_idx_0_inverse_dist_EN_sum'] + train['mole_idx_1_inverse_dist_EN_sum'])\n",
    "\n",
    "test['mole_idx_0_inverse_dist_EN_sum'] = 1 / (test.groupby(['molecule_name', 'atom_index_0'])['inverse_dist_EN'].transform('sum'))\n",
    "test['mole_idx_1_inverse_dist_EN_sum'] = 1 / (test.groupby(['molecule_name', 'atom_index_1'])['inverse_dist_EN'].transform('sum'))\n",
    "test['combine_inverse_dist_EN'] = test['mole_idx_0_inverse_dist_EN_sum'] * test['mole_idx_1_inverse_dist_EN_sum'] / (test['mole_idx_0_inverse_dist_EN_sum'] + test['mole_idx_1_inverse_dist_EN_sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)\n",
    "\n",
    "print('Train dataset shape is -> rows: {} cols:{}'.format(train.shape[0],train.shape[1]))\n",
    "print(f'Exe time: {(time.time() - start_time)/60:.2} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4658147, 123)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 870.70 Mb (75.5% reduction)\n",
      "Mem. usage decreased to 463.56 Mb (75.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns = {'type_x': 'type'}, inplace = True)\n",
    "test.rename(columns = {'type_x': 'type'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['multiply_mulliken'] = train['mulliken_atom_0'] * train['mulliken_atom_1']\n",
    "test['multiply_mulliken'] = test['mulliken_atom_0'] * test['mulliken_atom_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('E:/kaggle/Molecular_properties/Data_use/train_QM9_bonds_neighbor_ready.csv')\n",
    "test.to_csv('E:/kaggle/Molecular_properties/Data_use/test_QM9_bonds_neighbor_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv('E:/kaggle/Molecular_properties/Data_use/y_tr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_target = {'y_tr': y_tr}\n",
    "df_target = pd.DataFrame(dict_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace = True)\n",
    "test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_toDrop = ['molecule_name', \n",
    "               'atom_index_0', \n",
    "               'atom_index_1',\n",
    "               'atom_index_0_closest',\n",
    "               'atom_index_1_closest',\n",
    "               'atom_0',\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['molecule_name', 'atom_0_closest', 'atom_1_closest', 'atom_0',\n",
       "       'atom_1', 'bond_0_0closest', 'bond_1_1closest', 'bond_0_1closest',\n",
       "       'bond_1_0closest', 'bond_1closest_0closest'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes(include = 'object').columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#molecules = train.pop('molecule_name')\n",
    "#train.drop(['atom_index_0', 'atom_index_1', 'atom_index_0_closest', 'atom_index_1_closest', 'atom_0'], axis = 1, inplace = True)\n",
    "#test.drop(cols_toDrop, axis=1, inplace = True)\n",
    "\n",
    "#y_tr = train.pop('scalar_coupling_constant')\n",
    "categorical_features = [#'type', \n",
    "                        'atom_1', 'atom_0_closest', 'atom_1_closest', 'bond_0_0closest', 'bond_1_1closest', 'bond_0_1closest',\n",
    "       'bond_1_0closest', 'bond_1closest_0closest',]\n",
    "\n",
    "#Label Encoding\n",
    "for f in categorical_features:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "    train[f] = lbl.transform(list(train[f].values))\n",
    "    test[f] = lbl.transform(list(test[f].values))\n",
    "    \n",
    "types = train['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = train.pop('molecule_name')\n",
    "X_test.drop(['atom_index_0', 'atom_index_1'], axis = 1, inplace = True)\n",
    "test_test.drop(cols_toDrop, axis=1, inplace = True)\n",
    "\n",
    "y_tr = train.pop('scalar_coupling_constant')\n",
    "categorical_features = ['type', 'atom_1']\n",
    "\n",
    "#Label Encoding\n",
    "for f in ['type', 'atom_1']:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(X_test[f].values) + list(X_test[f].values))\n",
    "    X_test[f] = lbl.transform(list(X_test[f].values))\n",
    "    test_test[f] = lbl.transform(list(test_test[f].values))\n",
    "    \n",
    "types = train['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_tr = train_temp.pop('scalar_coupling_constant')\n",
    "df_molecules = pd.DataFrame(train['type'].copy())\n",
    "df_molecules['molecule_name'] = molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_molecules.to_csv('E:/kaggle/Molecular_properties/molecules.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_molecules = pd.read_csv('E:/kaggle/Molecular_properties/Data_use/molecules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteratively find the best features by type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are duplicated columns in the training set. We want to find out them to reduce feature filtering time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDuplicateColumns(df):\n",
    "    duplicateColumnNames = set()\n",
    "    goodCol = set()\n",
    "    \n",
    "    for x in range(df.shape[1]):\n",
    "        col = df.iloc[:, x]\n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "            otherCol = df.iloc[:, y]\n",
    "            if col.equals(otherCol):\n",
    "                found = True\n",
    "                goodCol.add(df.columns.values[x])\n",
    "                duplicateColumnNames.add(df.columns.values[y])\n",
    "            \n",
    "                \n",
    "    return list(duplicateColumnNames), list(goodCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection according to different types of couplings. We use 3 fold validation scheme basically to save as much time as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_short = pd.DataFrame({'ind': list(train.index), 'type': train['type'].values, 'oof': [0] * len(train), 'target': y_tr.values})\n",
    "X_short_test = pd.DataFrame({'ind': list(test.index), 'type': test['type'].values, 'prediction': [0] * len(test)})\n",
    "types_iterate = train['type'].unique()\n",
    "len(types_iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 200,                           #initial 200                                     \n",
    "          'min_child_samples': 79,                      #initial 79          \n",
    "          'objective': 'huber',                                        \n",
    "          #'max_depth': -1,                                    \n",
    "          'colsample_bytree': 0.9,                    # 0.9\n",
    "          'subsample': 0.8,                            #initial 0.8\n",
    "          'learning_rate': 0.25,                        # 0.25        \n",
    "          \"metric\": 'mae',                                       \n",
    "          'reg_alpha': 0.1,                            #initial 0.1       \n",
    "          'reg_lambda': 0.3                           #initial 0.3                              \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "gkf = GroupKFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[0]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:2000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "            \n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=1000)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_cols = [cos_0, cos_0_1, distance_1, distance_0, mulliken_closest_1, n_bonds_closest_1, atom_closest_1, mulliken_closest_0\n",
    "#]\n",
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_0 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_0.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type0_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[1]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:2000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "            \n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=1000)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_1 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_1.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type1_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[2]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:2000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "            \n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=500)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_2 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_2.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type2_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[3]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:2000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "\n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=500)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_3 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_3.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type3_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[4]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:2000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "\n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=500)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_4 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_4.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type4_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[5]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:1000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "\n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=500)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_5 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_5.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type5_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[6]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:2000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "\n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=500)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_6 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_6.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type6_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = types_iterate[7]\n",
    "X_t = train.loc[train['type'] == t][:25000]\n",
    "X_test_t = test.loc[test['type'] == t][:1000]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target'][:25000]\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name'][:25000]\n",
    "        \n",
    "features = [col for col in train.columns.values if col not in badcol]\n",
    "col_tokeep = ['type', 'dist', 'multiply_mulliken', 'rad_dist_diff']\n",
    "scores = [-1., -1., -1., -1.]\n",
    "duplicate_features, _ = getDuplicateColumns(X_t[features])\n",
    "\n",
    "for iteration in range(28):\n",
    "    print(f'Round {iteration}:')\n",
    "    score_best = 100\n",
    "    index_best = 0\n",
    "    number = 0\n",
    "    for index in range(len(features)):\n",
    "        if features[index] in col_tokeep:\n",
    "            continue\n",
    "        if len(X_t[features[index]].unique()) == 1:\n",
    "            continue\n",
    "        if features[index] in duplicate_features:\n",
    "            continue\n",
    "\n",
    "        print(f'{number} feature {features[index]} started at {time.ctime()}')\n",
    "        \n",
    "        number = number + 1\n",
    "        features_totest = col_tokeep.copy()\n",
    "        features_totest.append(features[index])\n",
    "        X_t_t = X_t[features_totest]\n",
    "        X_test_t_t = X_test_t[features_totest]\n",
    "        #y_t = y_tr[:40000]\n",
    "        #molecules_t = df_molecules[:40000]['molecule_name']\n",
    "\n",
    "        result_dict_lgb = train_model_regression(X=X_t_t, X_test=X_test_t_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='mae', plot_feature_importance=False,\n",
    "                                                          verbose=500, early_stopping_rounds=500, n_estimators=500)\n",
    "        score_mean = np.mean(result_dict_lgb['scores'])\n",
    "        if score_mean < score_best:\n",
    "            score_best = score_mean\n",
    "            index_best = index\n",
    "\n",
    "    col_tokeep.append(features[index_best])\n",
    "    scores.append(score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_feature = {'feature': col_tokeep, 'score': scores}\n",
    "df_features_7 = pd.DataFrame(dict_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_7.to_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type7_bonds_QM9_inver_neighbor_huber.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_test = [col for col in train.columns.values if col not in ['molecule_name', 'atom_index_0', 'atom_index_1', 'atom_0',\n",
    "                                                              'atom_1', 'type_0', 'atom_x', 'atom_y',\n",
    "                                                                'x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1',\n",
    "                                                                'x_closest_1', 'y_closest_1', 'z_closest_1',\n",
    "                                                                'x_closest_0','y_closest_0', 'z_closest_0',\n",
    "                                                                'mulliken_mean',\n",
    "                                                                #'Cv', 'H', 'U', 'U0', 'zpve', 'r2', 'alpha',\n",
    "                                                               'dist_x', 'dist_y', 'dist_z',\n",
    "                                                                'EN_0', 'rad_0',\n",
    "                                                              'oof_fc', \n",
    "                                                              'oof_sd', \n",
    "                                                              'oof_pso', \n",
    "                                                              'oof_dso'\n",
    "                                                               ]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = list(df_features_0['feature'].values) + list(df_features_1['feature'].values) + list(df_features_2['feature'].values) + list(df_features_3['feature'].values) + list(df_features_4['feature'].values) + list(df_features_5['feature'].values) + list(df_features_6['feature'].values) + list(df_features_7['feature'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tokeep = set(features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokeep = train[features_tokeep]\n",
    "test_tokeep = test[features_tokeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('E:/kaggle/Molecular_properties/Data_use/train_bonds_QM9_neighbor_merge.csv')\n",
    "test.to_csv('E:/kaggle/Molecular_properties/Data_use/test_bonds_QM9_neighbor_merge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Features by types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_short = pd.DataFrame({'ind': list(train.index), 'type': train['type'].values, \n",
    "                        'oof_fc': [0] * len(train), 'oof_sd': [0] * len(train), 'oof_pso': [0] * len(train), 'oof_dso': [0] * len(train),\n",
    "                        'target_fc': y_fc.values, 'target_sd': y_sd.values, 'target_pso': y_pso.values, 'target_dso': y_dso.values})\n",
    "X_short_test = pd.DataFrame({'ind': list(test.index), 'type': test['type'].values, \n",
    "                             'prediction_fc': [0] * len(test), 'prediction_sd': [0] * len(test), 'prediction_pso': [0] * len(test), 'prediction_dso': [0] * len(test) })\n",
    "types_iterate = train['type'].unique()\n",
    "len(types_iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 200,                           #initial 200                                     \n",
    "          'min_data_in_leaf': 79,                      #initial 79          \n",
    "          'objective': 'huber',                                        \n",
    "          #'max_depth': -1,                                    \n",
    "          'colsample_bytree': 0.9,                    # 0.9\n",
    "          'subsample': 0.8,                            #initial 0.8\n",
    "          'learning_rate': 0.25,                        # 0.25        \n",
    "          \"metric\": 'mae',                                       \n",
    "          'reg_alpha': 0.1,                            #initial 0.1       \n",
    "          'reg_lambda': 0.3                           #initial 0.3                              \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_secondary(X_short_secondary, X_short_test_secondary, types_iterate):\n",
    "    features = ['fc', \n",
    "                #'sd', \n",
    "                #'pso', \n",
    "                #'dso'\n",
    "               ]\n",
    "    for feature in features:\n",
    "        \n",
    "        print('Training of feature ' + feature)\n",
    "        label = 'target_' + feature\n",
    "        train_secondary_feature = 'oof_' + feature\n",
    "        test_secondary_feature = 'prediction_' + feature\n",
    "        i = 0\n",
    "        \n",
    "        for t in types_iterate:\n",
    "            print(f'Training of type {t}')\n",
    "            df_features = pd.read_csv(f'E:/kaggle/Molecular_properties/good_features/good_ft_type{i}_bonds_QM9_inver_neighbor_huber.csv')\n",
    "            good_features = df_features['feature']\n",
    "            \n",
    "            X_t = train[good_features].loc[train['type'] == t]\n",
    "            X_test_t = test[good_features].loc[test['type'] == t]\n",
    "            y_t = X_short_secondary.loc[X_short['type'] == t, label]\n",
    "            molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "            result_dict_lgb_oof = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                                      folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=False,\n",
    "                                                                      verbose=1000, early_stopping_rounds=500, n_estimators=10000)\n",
    "\n",
    "            X_short_secondary.loc[X_short_secondary['type'] == t, train_secondary_feature] = result_dict_lgb_oof['oof']\n",
    "            X_short_test_secondary.loc[X_short_test_secondary['type'] == t, test_secondary_feature] = result_dict_lgb_oof['prediction']\n",
    "            \n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_secondary(X_short, X_short_test, types_iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['oof_fc'] = X_short['oof_fc']\n",
    "test['oof_fc'] = X_short_test['prediction_fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['oof_sd'] = X_short['oof_sd']\n",
    "test['oof_sd'] = X_short_test['prediction_sd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['oof_pso'] = X_short['oof_pso']\n",
    "test['oof_pso'] = X_short_test['prediction_pso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['oof_dso'] = X_short['oof_dso']\n",
    "test['oof_dso'] = X_short_test['prediction_dso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train by types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_short = pd.DataFrame({'ind': list(train.index), 'type': train['type'].values, 'oof': [0] * len(train), 'target': y_tr.values})\n",
    "X_short_test = pd.DataFrame({'ind': list(test.index), 'type': test['type'].values, 'prediction': [0] * len(test)})\n",
    "types_iterate = train['type'].unique()\n",
    "len(types_iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped CV score: 0.6484  10000 step Secondary feature all: 0.1605   10000 step Secondary by type, after feature selection: 0.2411\n",
    "#10000 step Secondary from all, after feature selection: 0.2594      \n",
    "#'mae': w/0 fc: 0.1643\n",
    "#'huber' w/o fc: -0.3177\n",
    "\n",
    "t = types_iterate[0]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type0_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "#good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_0 = result_dict_lgb['feature_importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_importance_0[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_toDrop = list(feature_importance_0[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[-15:].index)\n",
    "cols_toDrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('E:/kaggle/Molecular_properties/feature_importance_type0_bonds_QM9_regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped CV score: -0.9384   -1.3241  Secondary feature by type, after feature selection: -1.2661\n",
    "#10000 step Secondary from all: -1.218\n",
    "#'huber': w 'huber' fc: -1.7444\n",
    "\n",
    "t = types_iterate[1]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type1_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grouped CV score: 0.0191   -0.7083  Secondary feature by type, after feature selection: -0.7227\n",
    "#10000 step Secondary from all: -0.7321\n",
    "#'huber': w'huber' fc: -1.0626\n",
    "t = types_iterate[2]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type2_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 200,                           #initial 200                                     \n",
    "          'min_child_samples': 79,                      #initial 79          \n",
    "          'objective': 'huber',                                        \n",
    "          #'max_depth': -1,                                    \n",
    "          'colsample_bytree': 0.9,                    # 0.9\n",
    "          'subsample': 0.8,                            #initial 0.8\n",
    "          'eta': 0.15,                        # 0.25        \n",
    "          \"metric\": 'mae',                                       \n",
    "          'reg_alpha': 0.1,                            #initial 0.1       \n",
    "          'reg_lambda': 0.3                           #initial 0.3                              \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped CV score: -0.7305   -1.1433  Secondary feature by type, after feature selection: -1.3263\n",
    "#10000 step Secondary from all: -1.2675\n",
    "#'huber': w'huber' fc: -1.8810\n",
    "t = types_iterate[3]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type3_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped CV score: -0.2570   -0.5576   Secondary feature by type, after feature selection: -0.6112\n",
    "#10000 step Secondary from all: -0.5765\n",
    "#'huber': w 'huber' fc: -1.2730\n",
    "t = types_iterate[4]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type4_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped CV score: -0.6655  -1.0659   Secondary feature by type, after feature selection: -1.0359\n",
    "#10000 step Secondary from all: -1.0109\n",
    "#'huber': w/o fc: -1.8651 \n",
    "t = types_iterate[5]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type5_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "#good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped CV score: -0.2060  -0.4448    Secondary feature by type, after feature selection: -0.4463\n",
    "#'huber': w 'huber' fc: -1.2960\n",
    "t = types_iterate[6]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type6_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 125,                                     \n",
    "          'min_data_in_leaf': 79,                                \n",
    "          'objective': 'regression',                                  # best: 'regression'         \n",
    "          'max_depth': -1,                                     # best: -1 \n",
    "          'learning_rate': 0.2,                                \n",
    "          \"boosting\": \"gbdt\",             \n",
    "          \"bagging_freq\": 1,                                   # best 1  \n",
    "          \"bagging_fraction\": 0.9,                             # best  0.9  \n",
    "          'feature_fraction': 1,                             # best 1\n",
    "          \"bagging_seed\": 11,                                    \n",
    "          \"metric\": 'mae',                                       \n",
    "          \"verbosity\": -1,                                       \n",
    "          'reg_alpha': 0.1,                                    # best 0.1\n",
    "          'reg_lambda': 0.05                                   # best 0.05                       \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped CV score: -1.2157   -1.4679    Secondary feature by type, after feature selection: -1.5517\n",
    "#'huber': w 'huber' fc: -2.28\n",
    "t = types_iterate[7]\n",
    "print(f'Training of type {t}')\n",
    "\n",
    "df_features = pd.read_csv('E:/kaggle/Molecular_properties/good_features/good_ft_type7_bonds_QM9_inver_neighbor_huber.csv')\n",
    "good_features = list(df_features['feature'].values)\n",
    "good_features.append('oof_fc')\n",
    "\n",
    "X_t = train[good_features].loc[train['type'] == t]\n",
    "X_test_t = test[good_features].loc[test['type'] == t]\n",
    "y_t = X_short.loc[X_short['type'] == t, 'target']\n",
    "molecules_t = df_molecules.loc[df_molecules['type'] == t, 'molecule_name']\n",
    "result_dict_lgb = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, molecules = molecules_t,\n",
    "                                                          folds=gkf, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                          verbose=1000, early_stopping_rounds=500, n_estimators=20000)\n",
    "\n",
    "X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb['oof']\n",
    "X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('E:/kaggle/Molecular_properties/champs-scalar-coupling/sample_submission.csv', index_col='id')\n",
    "benchmark = sample_submission.copy()\n",
    "benchmark.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4658147</td>\n",
       "      <td>15.275014760451096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4658148</td>\n",
       "      <td>196.270488138716075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4658149</td>\n",
       "      <td>12.060166492061617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4658150</td>\n",
       "      <td>192.946203272756463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4658151</td>\n",
       "      <td>13.630952233646905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  scalar_coupling_constant\n",
       "0  4658147        15.275014760451096\n",
       "1  4658148       196.270488138716075\n",
       "2  4658149        12.060166492061617\n",
       "3  4658150       192.946203272756463\n",
       "4  4658151        13.630952233646905"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark['scalar_coupling_constant'] = X_short_test['prediction']\n",
    "benchmark.to_csv('train_type_feature_type_bonds_QM9_fc.csv', index=False)\n",
    "benchmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type_dict = {'1JHC': 0, '1JHN': 1, '2JHC': 2, '2JHH': 3, '2JHN': 4, '3JHC': 5, '3JHH': 6, '3JHN': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('E:/kaggle/Molecular_properties/Data_use/train_20190730_w_SCC.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
